{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNP1G5gMI7XmoWpzsSQgZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allisonandreyev/WhisperQuantization/blob/master/Quantization_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading whisper cpp\n",
        "%cd\n",
        "!git clone https://github.com/ggerganov/whisper.cpp.git\n",
        "%cd whisper.cpp\n",
        "!mkdir build && cd build && cmake .. && make\n",
        "!sh ./models/download-ggml-model.sh base.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N--kkSEPEXuZ",
        "outputId": "063994b0-c546-40b9-89b4-bb2371d693db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Cloning into 'whisper.cpp'...\n",
            "remote: Enumerating objects: 16122, done.\u001b[K\n",
            "remote: Counting objects: 100% (2825/2825), done.\u001b[K\n",
            "remote: Compressing objects: 100% (544/544), done.\u001b[K\n",
            "remote: Total 16122 (delta 2404), reused 2281 (delta 2281), pack-reused 13297 (from 4)\u001b[K\n",
            "Receiving objects: 100% (16122/16122), 20.38 MiB | 5.24 MiB/s, done.\n",
            "Resolving deltas: 100% (11062/11062), done.\n",
            "/root/whisper.cpp\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (3.0s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /root/whisper.cpp/build\n",
            "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32m\u001b[1mLinking CXX shared library libggml-base.so\u001b[0m\n",
            "[ 19%] Built target ggml-base\n",
            "[ 21%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX shared library libggml-cpu.so\u001b[0m\n",
            "[ 40%] Built target ggml-cpu\n",
            "[ 42%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32m\u001b[1mLinking CXX shared library libggml.so\u001b[0m\n",
            "[ 45%] Built target ggml\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared library libwhisper.so\u001b[0m\n",
            "[ 50%] Built target whisper\n",
            "[ 52%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-whisper.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 61%] Built target common\n",
            "[ 64%] \u001b[32mBuilding CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-cli\u001b[0m\n",
            "[ 66%] Built target whisper-cli\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-bench\u001b[0m\n",
            "[ 71%] Built target whisper-bench\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-server\u001b[0m\n",
            "[ 76%] Built target whisper-server\n",
            "[ 78%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/quantize\u001b[0m\n",
            "[ 80%] Built target quantize\n",
            "[ 83%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/main\u001b[0m\n",
            "[ 85%] Built target main\n",
            "[ 88%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/bench\u001b[0m\n",
            "[ 90%] Built target bench\n",
            "[ 92%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/stream.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/stream\u001b[0m\n",
            "[ 95%] Built target stream\n",
            "[ 97%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/command.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/command\u001b[0m\n",
            "[100%] Built target command\n",
            "Downloading ggml model base.en from 'https://huggingface.co/ggerganov/whisper.cpp' ...\n",
            "ggml-base.en.bin    100%[===================>] 141.11M   203MB/s    in 0.7s    \n",
            "Done! Model 'base.en' saved in '/root/whisper.cpp/models/ggml-base.en.bin'\n",
            "You can now use it like this:\n",
            "\n",
            "  $ ./build/bin/whisper-cli -m /root/whisper.cpp/models/ggml-base.en.bin -f samples/jfk.wav\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the project\n",
        "!cmake -B build\n",
        "!cmake --build build --config Release\n",
        "\n",
        "# transcribe an audio file\n",
        "!./build/bin/whisper-cli -f samples/jfk.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JhgQBSlAKf3p",
        "outputId": "bcda8836-0023-4b61-f3e0-c4db6cc1e034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (0.2s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /root/whisper.cpp/build\n",
            "[ 19%] Built target ggml-base\n",
            "[ 40%] Built target ggml-cpu\n",
            "[ 45%] Built target ggml\n",
            "[ 50%] Built target whisper\n",
            "[ 61%] Built target common\n",
            "[ 66%] Built target whisper-cli\n",
            "[ 71%] Built target whisper-bench\n",
            "[ 76%] Built target whisper-server\n",
            "[ 80%] Built target quantize\n",
            "[ 85%] Built target main\n",
            "[ 90%] Built target bench\n",
            "[ 95%] Built target stream\n",
            "[100%] Built target command\n",
            "whisper_init_from_file_with_params_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_init_with_params_no_state: use gpu    = 1\n",
            "whisper_init_with_params_no_state: flash attn = 0\n",
            "whisper_init_with_params_no_state: gpu_device = 0\n",
            "whisper_init_with_params_no_state: dtw        = 0\n",
            "whisper_init_with_params_no_state: devices    = 1\n",
            "whisper_init_with_params_no_state: backends   = 1\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2 (base)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: n_langs       = 99\n",
            "whisper_model_load:      CPU total size =   147.37 MB\n",
            "whisper_model_load: model size    =  147.37 MB\n",
            "whisper_backend_init_gpu: no GPU found\n",
            "whisper_init_state: kv self size  =    6.29 MB\n",
            "whisper_init_state: kv cross size =   18.87 MB\n",
            "whisper_init_state: kv pad  size  =    3.15 MB\n",
            "whisper_init_state: compute buffer (conv)   =   16.26 MB\n",
            "whisper_init_state: compute buffer (encode) =   85.86 MB\n",
            "whisper_init_state: compute buffer (cross)  =    4.65 MB\n",
            "whisper_init_state: compute buffer (decode) =   96.35 MB\n",
            "\n",
            "system_info: n_threads = 2 / 2 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "\n",
            "main: processing 'samples/jfk.wav' (176000 samples, 11.0 sec), 2 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n",
            "\n",
            "\n",
            "[00:00:00.000 --> 00:00:11.000]   And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.\n",
            "\n",
            "\n",
            "whisper_print_timings:     load time =   150.90 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =    43.91 ms\n",
            "whisper_print_timings:   sample time =   242.37 ms /   131 runs (    1.85 ms per run)\n",
            "whisper_print_timings:   encode time =  8271.26 ms /     1 runs ( 8271.26 ms per run)\n",
            "whisper_print_timings:   decode time =    27.56 ms /     2 runs (   13.78 ms per run)\n",
            "whisper_print_timings:   batchd time =  1055.24 ms /   125 runs (    8.44 ms per run)\n",
            "whisper_print_timings:   prompt time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =  9857.24 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe an audio file and append the output to pred.txt\n",
        "!./build/bin/whisper-cli -f samples/jfk.wav -otxt >> pred.txt\n",
        "!cat pred.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zik8_EmEiI0d",
        "outputId": "b02aa914-1dc0-4b73-9405-a50f72d11cba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper_init_from_file_with_params_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_init_with_params_no_state: use gpu    = 1\n",
            "whisper_init_with_params_no_state: flash attn = 0\n",
            "whisper_init_with_params_no_state: gpu_device = 0\n",
            "whisper_init_with_params_no_state: dtw        = 0\n",
            "whisper_init_with_params_no_state: devices    = 1\n",
            "whisper_init_with_params_no_state: backends   = 1\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2 (base)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: n_langs       = 99\n",
            "whisper_model_load:      CPU total size =   147.37 MB\n",
            "whisper_model_load: model size    =  147.37 MB\n",
            "whisper_backend_init_gpu: no GPU found\n",
            "whisper_init_state: kv self size  =    6.29 MB\n",
            "whisper_init_state: kv cross size =   18.87 MB\n",
            "whisper_init_state: kv pad  size  =    3.15 MB\n",
            "whisper_init_state: compute buffer (conv)   =   16.26 MB\n",
            "whisper_init_state: compute buffer (encode) =   85.86 MB\n",
            "whisper_init_state: compute buffer (cross)  =    4.65 MB\n",
            "whisper_init_state: compute buffer (decode) =   96.35 MB\n",
            "\n",
            "system_info: n_threads = 2 / 2 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "\n",
            "main: processing 'samples/jfk.wav' (176000 samples, 11.0 sec), 2 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n",
            "\n",
            "output_txt: saving output to 'samples/jfk.wav.txt'\n",
            "\n",
            "whisper_print_timings:     load time =   161.29 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =    45.65 ms\n",
            "whisper_print_timings:   sample time =   250.23 ms /   131 runs (    1.91 ms per run)\n",
            "whisper_print_timings:   encode time =  8207.46 ms /     1 runs ( 8207.46 ms per run)\n",
            "whisper_print_timings:   decode time =    27.07 ms /     2 runs (   13.54 ms per run)\n",
            "whisper_print_timings:   batchd time =  1063.54 ms /   125 runs (    8.51 ms per run)\n",
            "whisper_print_timings:   prompt time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =  9817.42 ms\n",
            "\n",
            "[00:00:00.000 --> 00:00:11.000]   And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quantize a model with Q5_0 method\n",
        "!cmake -B build\n",
        "!cmake --build build --config Release\n",
        "!./build/bin/quantize models/ggml-base.en.bin models/ggml-base.en-q6_0.bin q6_0\n",
        "\n",
        "!./build/bin/whisper-cli -m models/ggml-base.en-q6_0.bin ./samples/gb0.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6pvC2fKf4Rz",
        "outputId": "2d487653-8cf6-48f2-aceb-7cfe708c80f9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (0.2s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /root/whisper.cpp/build\n",
            "[ 19%] Built target ggml-base\n",
            "[ 40%] Built target ggml-cpu\n",
            "[ 45%] Built target ggml\n",
            "[ 50%] Built target whisper\n",
            "[ 61%] Built target common\n",
            "[ 66%] Built target whisper-cli\n",
            "[ 71%] Built target whisper-bench\n",
            "[ 76%] Built target whisper-server\n",
            "[ 80%] Built target quantize\n",
            "[ 85%] Built target main\n",
            "[ 90%] Built target bench\n",
            "[ 95%] Built target stream\n",
            "[100%] Built target command\n",
            "ggml_parse_ftype: unknown ftype 'q6_0'\n",
            "whisper_model_quantize: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_quantize: n_vocab       = 51864\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 1999\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "ggml_common_quantize_0: invalid model type -1\n",
            "whisper_model_quantize: failed to quantize model 'models/ggml-base.en.bin'\n",
            "main: failed to quantize model from 'models/ggml-base.en.bin'\n",
            "error: input file not found './samples/gb0.wav'\n",
            "error: no input files specified\n",
            "\n",
            "usage: ./build/bin/whisper-cli [options] file0 file1 ...\n",
            "supported audio formats: flac, mp3, ogg, wav\n",
            "\n",
            "options:\n",
            "  -h,        --help              [default] show this help message and exit\n",
            "  -t N,      --threads N         [2      ] number of threads to use during computation\n",
            "  -p N,      --processors N      [1      ] number of processors to use during computation\n",
            "  -ot N,     --offset-t N        [0      ] time offset in milliseconds\n",
            "  -on N,     --offset-n N        [0      ] segment index offset\n",
            "  -d  N,     --duration N        [0      ] duration of audio to process in milliseconds\n",
            "  -mc N,     --max-context N     [-1     ] maximum number of text context tokens to store\n",
            "  -ml N,     --max-len N         [0      ] maximum segment length in characters\n",
            "  -sow,      --split-on-word     [false  ] split on word rather than on token\n",
            "  -bo N,     --best-of N         [5      ] number of best candidates to keep\n",
            "  -bs N,     --beam-size N       [5      ] beam size for beam search\n",
            "  -ac N,     --audio-ctx N       [0      ] audio context size (0 - all)\n",
            "  -wt N,     --word-thold N      [0.01   ] word timestamp probability threshold\n",
            "  -et N,     --entropy-thold N   [2.40   ] entropy threshold for decoder fail\n",
            "  -lpt N,    --logprob-thold N   [-1.00  ] log probability threshold for decoder fail\n",
            "  -nth N,    --no-speech-thold N [0.60   ] no speech threshold\n",
            "  -tp,       --temperature N     [0.00   ] The sampling temperature, between 0 and 1\n",
            "  -tpi,      --temperature-inc N [0.20   ] The increment of temperature, between 0 and 1\n",
            "  -debug,    --debug-mode        [false  ] enable debug mode (eg. dump log_mel)\n",
            "  -tr,       --translate         [false  ] translate from source language to english\n",
            "  -di,       --diarize           [false  ] stereo audio diarization\n",
            "  -tdrz,     --tinydiarize       [false  ] enable tinydiarize (requires a tdrz model)\n",
            "  -nf,       --no-fallback       [false  ] do not use temperature fallback while decoding\n",
            "  -otxt,     --output-txt        [false  ] output result in a text file\n",
            "  -ovtt,     --output-vtt        [false  ] output result in a vtt file\n",
            "  -osrt,     --output-srt        [false  ] output result in a srt file\n",
            "  -olrc,     --output-lrc        [false  ] output result in a lrc file\n",
            "  -owts,     --output-words      [false  ] output script for generating karaoke video\n",
            "  -fp,       --font-path         [/System/Library/Fonts/Supplemental/Courier New Bold.ttf] path to a monospace font for karaoke video\n",
            "  -ocsv,     --output-csv        [false  ] output result in a CSV file\n",
            "  -oj,       --output-json       [false  ] output result in a JSON file\n",
            "  -ojf,      --output-json-full  [false  ] include more information in the JSON file\n",
            "  -of FNAME, --output-file FNAME [       ] output file path (without file extension)\n",
            "  -np,       --no-prints         [false  ] do not print anything other than the results\n",
            "  -ps,       --print-special     [false  ] print special tokens\n",
            "  -pc,       --print-colors      [false  ] print colors\n",
            "  -pp,       --print-progress    [false  ] print progress\n",
            "  -nt,       --no-timestamps     [false  ] do not print timestamps\n",
            "  -l LANG,   --language LANG     [en     ] spoken language ('auto' for auto-detect)\n",
            "  -dl,       --detect-language   [false  ] exit after automatically detecting language\n",
            "             --prompt PROMPT     [       ] initial prompt (max n_text_ctx/2 tokens)\n",
            "  -m FNAME,  --model FNAME       [models/ggml-base.en-q6_0.bin] model path\n",
            "  -f FNAME,  --file FNAME        [       ] input audio file path\n",
            "  -oved D,   --ov-e-device DNAME [CPU    ] the OpenVINO device used for encode inference\n",
            "  -dtw MODEL --dtw MODEL         [       ] compute token-level timestamps\n",
            "  -ls,       --log-score         [false  ] log best decoder scores of tokens\n",
            "  -ng,       --no-gpu            [false  ] disable GPU\n",
            "  -fa,       --flash-attn        [false  ] flash attention\n",
            "  -sns,      --suppress-nst      [false  ] suppress non-speech tokens\n",
            "  --suppress-regex REGEX         [       ] regular expression matching tokens to suppress\n",
            "  --grammar GRAMMAR              [       ] GBNF grammar to guide decoding\n",
            "  --grammar-rule RULE            [       ] top-level GBNF grammar rule name\n",
            "  --grammar-penalty N            [100.0  ] scales down logits of nongrammar tokens\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading huggingface dataset\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/datasets/openslr/librispeech_asr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dhC5f2k7F0X0",
        "outputId": "fee3e116-e16f-4c5e-bf58-088530db210e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'librispeech_asr'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 222 (delta 5), reused 0 (delta 0), pack-reused 74 (from 1)\u001b[K\n",
            "Receiving objects: 100% (222/222), 51.51 KiB | 10.30 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading WER program\n",
        "%cd\n",
        "!git clone https://github.com/ins8ai/wer.git\n",
        "%cd wer/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "-57eOgHKGUj0",
        "outputId": "05685527-41ac-49f9-ddcb-1d5314ff5bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Cloning into 'wer'...\n",
            "remote: Enumerating objects: 401, done.\u001b[K\n",
            "remote: Counting objects: 100% (401/401), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 401 (delta 259), reused 391 (delta 253), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (401/401), 491.28 KiB | 9.45 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n",
            "/root/wer\n",
            "Collecting aiohttp==3.8.6 (from -r requirements.txt (line 1))\n",
            "  Downloading aiohttp-3.8.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 2))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 3))\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==23.1.0 (from -r requirements.txt (line 4))\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting certifi==2023.7.22 (from -r requirements.txt (line 5))\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.3.0 (from -r requirements.txt (line 6))\n",
            "  Downloading charset_normalizer-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Collecting click==8.1.7 (from -r requirements.txt (line 7))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting datasets==2.14.5 (from -r requirements.txt (line 8))\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill==0.3.7 (from -r requirements.txt (line 9))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting evaluate==0.4.1 (from -r requirements.txt (line 10))\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting filelock==3.12.4 (from -r requirements.txt (line 11))\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting frozenlist==1.4.0 (from -r requirements.txt (line 12))\n",
            "  Downloading frozenlist-1.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting fsspec==2023.6.0 (from -r requirements.txt (line 13))\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting huggingface-hub==0.18.0 (from -r requirements.txt (line 14))\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting idna==3.4 (from -r requirements.txt (line 15))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting iter-tools==0.0.2 (from -r requirements.txt (line 16))\n",
            "  Downloading iter_tools-0.0.2-py3-none-any.whl.metadata (433 bytes)\n",
            "Collecting jiwer==3.0.3 (from -r requirements.txt (line 17))\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting more-itertools==10.1.0 (from -r requirements.txt (line 18))\n",
            "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting multidict==6.0.4 (from -r requirements.txt (line 19))\n",
            "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting multiprocess==0.70.15 (from -r requirements.txt (line 20))\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting numpy==1.26.1 (from -r requirements.txt (line 21))\n",
            "  Downloading numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.2 (from -r requirements.txt (line 22))\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.1.1 (from -r requirements.txt (line 23))\n",
            "  Downloading pandas-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pyarrow==13.0.0 (from -r requirements.txt (line 24))\n",
            "  Downloading pyarrow-13.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (2.8.2)\n",
            "Collecting pytz==2023.3.post1 (from -r requirements.txt (line 26))\n",
            "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.1 (from -r requirements.txt (line 27))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting rapidfuzz==3.4.0 (from -r requirements.txt (line 28))\n",
            "  Downloading rapidfuzz-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting regex==2023.10.3 (from -r requirements.txt (line 29))\n",
            "  Downloading regex-2023.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.31.0 (from -r requirements.txt (line 30))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting responses==0.18.0 (from -r requirements.txt (line 31))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting six==1.16.0 (from -r requirements.txt (line 32))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm==4.66.1 (from -r requirements.txt (line 33))\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer==0.9.0 (from -r requirements.txt (line 34))\n",
            "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting typing_extensions==4.8.0 (from -r requirements.txt (line 35))\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tzdata==2023.3 (from -r requirements.txt (line 36))\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting urllib3==2.0.6 (from -r requirements.txt (line 37))\n",
            "  Downloading urllib3-2.0.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting xxhash==3.4.1 (from -r requirements.txt (line 38))\n",
            "  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl==1.9.2 (from -r requirements.txt (line 39))\n",
            "  Downloading yarl-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Downloading aiohttp-3.8.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Downloading frozenlist-1.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iter_tools-0.0.2-py3-none-any.whl (2.7 kB)\n",
            "Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-13.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.0.6-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, xxhash, urllib3, tzdata, typing_extensions, tqdm, six, regex, rapidfuzz, PyYAML, packaging, numpy, multidict, more-itertools, iter-tools, idna, fsspec, frozenlist, filelock, dill, click, charset-normalizer, certifi, attrs, async-timeout, yarl, typer, requests, pyarrow, multiprocess, jiwer, aiosignal, responses, pandas, huggingface-hub, aiohttp, datasets, evaluate\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.1.0\n",
            "    Uninstalling multidict-6.1.0:\n",
            "      Successfully uninstalled multidict-6.1.0\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 10.6.0\n",
            "    Uninstalling more-itertools-10.6.0:\n",
            "      Successfully uninstalled more-itertools-10.6.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.5.0\n",
            "    Uninstalling frozenlist-1.5.0:\n",
            "      Successfully uninstalled frozenlist-1.5.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.1.0\n",
            "    Uninstalling attrs-25.1.0:\n",
            "      Successfully uninstalled attrs-25.1.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.18.3\n",
            "    Uninstalling yarl-1.18.3:\n",
            "      Successfully uninstalled yarl-1.18.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.2\n",
            "    Uninstalling typer-0.15.2:\n",
            "      Successfully uninstalled typer-0.15.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.3.2\n",
            "    Uninstalling aiosignal-1.3.2:\n",
            "      Successfully uninstalled aiosignal-1.3.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.13\n",
            "    Uninstalling aiohttp-3.11.13:\n",
            "      Successfully uninstalled aiohttp-3.11.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 13.0.0 which is incompatible.\n",
            "dask-expr 1.1.21 requires pyarrow>=14.0.1, but you have pyarrow 13.0.0 which is incompatible.\n",
            "transformers 4.48.3 requires huggingface-hub<1.0,>=0.24.0, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "pylibcudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 13.0.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.6.0 which is incompatible.\n",
            "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "accelerate 1.3.0 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "google-genai 1.2.0 requires typing-extensions<5.0.0dev,>=4.11.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.1 which is incompatible.\n",
            "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.12.4 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.8.0 which is incompatible.\n",
            "openai 1.61.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.3.0 click-8.1.7 datasets-2.14.5 dill-0.3.7 evaluate-0.4.1 filelock-3.12.4 frozenlist-1.4.0 fsspec-2023.6.0 huggingface-hub-0.18.0 idna-3.4 iter-tools-0.0.2 jiwer-3.0.3 more-itertools-10.1.0 multidict-6.0.4 multiprocess-0.70.15 numpy-1.26.1 packaging-23.2 pandas-2.1.1 pyarrow-13.0.0 pytz-2023.3.post1 rapidfuzz-3.4.0 regex-2023.10.3 requests-2.31.0 responses-0.18.0 six-1.16.0 tqdm-4.66.1 typer-0.9.0 typing_extensions-4.8.0 tzdata-2023.3 urllib3-2.0.6 xxhash-3.4.1 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "six"
                ]
              },
              "id": "1f3e3d489a7f44918f98f1a34a00b34e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from datasets import load_dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Stream the dataset to avoid full download\n",
        "dataset_iter = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\", streaming=True)\n",
        "\n",
        "# Take only the first 100 samples\n",
        "dataset = list(dataset_iter.take(100))\n",
        "\n",
        "print(len(dataset))  # Should print 100\n",
        "print(dataset[0])  # Check the first sample\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "HKN3noaIjJLK",
        "outputId": "649116e3-5832-47cc-dd25-2cdd34443f3c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "{'file': '6930-75918-0000.flac', 'audio': {'path': '6930-75918-0000.flac', 'array': array([-6.10351562e-05,  9.15527344e-05,  1.06811523e-03, ...,\n",
            "       -2.19726562e-03, -1.13830566e-02, -8.81958008e-03]), 'sampling_rate': 16000}, 'text': 'CONCORD RETURNED TO ITS PLACE AMIDST THE TENTS', 'speaker_id': 6930, 'chapter_id': 75918, 'id': '6930-75918-0000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/whisper.cpp/\n",
        "max_files = 10\n",
        "current_file_count = 0\n",
        "whisper_path = \"/root/whisper.cpp/build/bin/whisper-cli\"\n",
        "model_path = \"/root/whisper.cpp/models/ggml-base.en.bin\"\n",
        "output_file = \"pred.txt\"\n",
        "reference_file = \"ref.txt\"\n",
        "audio_path = \"\"\n",
        "subprocess.run(f\"rm {output_file}\", shell=True)\n",
        "subprocess.run(f\"rm {reference_file}\", shell=True)\n",
        "\n",
        "\n",
        "for data in dataset:\n",
        "    if current_file_count >= max_files:\n",
        "        break\n",
        "    current_file_count += 1\n",
        "    audio_data = data[\"audio\"][\"array\"]\n",
        "    text_data = data[\"text\"]\n",
        "    print(audio_data)\n",
        "    print(text_data)\n",
        "    audio_data = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)\n",
        "    wavfile.write('tmp.wav', data['audio']['sampling_rate'], audio_data)\n",
        "\n",
        "    result = subprocess.run(\n",
        "        f\"{whisper_path} -m {model_path} -f tmp.wav -nt -np >> {output_file} 2>&1\",\n",
        "        shell=True\n",
        "    )\n",
        "    with open(reference_file, \"a\") as f:\n",
        "        f.write(text_data + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VNvhwuWBSZJC",
        "outputId": "e399efad-1c20-4e51-e1a8-a061822adaf5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/whisper.cpp\n",
            "[-6.10351562e-05  9.15527344e-05  1.06811523e-03 ... -2.19726562e-03\n",
            " -1.13830566e-02 -8.81958008e-03]\n",
            "CONCORD RETURNED TO ITS PLACE AMIDST THE TENTS\n",
            "[-0.00570679 -0.00732422  0.00512695 ...  0.00085449  0.0007019\n",
            "  0.00067139]\n",
            "THE ENGLISH FORWARDED TO THE FRENCH BASKETS OF FLOWERS OF WHICH THEY HAD MADE A PLENTIFUL PROVISION TO GREET THE ARRIVAL OF THE YOUNG PRINCESS THE FRENCH IN RETURN INVITED THE ENGLISH TO A SUPPER WHICH WAS TO BE GIVEN THE NEXT DAY\n",
            "[ 0.00091553  0.00115967  0.0010376  ...  0.00531006 -0.00634766\n",
            " -0.00198364]\n",
            "CONGRATULATIONS WERE POURED IN UPON THE PRINCESS EVERYWHERE DURING HER JOURNEY\n",
            "[ 0.00326538 -0.0027771  -0.00146484 ...  0.01327515  0.00387573\n",
            " -0.01300049]\n",
            "FROM THE RESPECT PAID HER ON ALL SIDES SHE SEEMED LIKE A QUEEN AND FROM THE ADORATION WITH WHICH SHE WAS TREATED BY TWO OR THREE SHE APPEARED AN OBJECT OF WORSHIP THE QUEEN MOTHER GAVE THE FRENCH THE MOST AFFECTIONATE RECEPTION FRANCE WAS HER NATIVE COUNTRY AND SHE HAD SUFFERED TOO MUCH UNHAPPINESS IN ENGLAND FOR ENGLAND TO HAVE MADE HER FORGET FRANCE\n",
            "[-0.00881958 -0.00198364  0.00518799 ...  0.00390625 -0.00436401\n",
            " -0.00341797]\n",
            "SHE TAUGHT HER DAUGHTER THEN BY HER OWN AFFECTION FOR IT THAT LOVE FOR A COUNTRY WHERE THEY HAD BOTH BEEN HOSPITABLY RECEIVED AND WHERE A BRILLIANT FUTURE OPENED BEFORE THEM\n",
            "[ 0.00057983 -0.00408936 -0.01113892 ...  0.0010376   0.00057983\n",
            " -0.00115967]\n",
            "THE COUNT HAD THROWN HIMSELF BACK ON HIS SEAT LEANING HIS SHOULDERS AGAINST THE PARTITION OF THE TENT AND REMAINED THUS HIS FACE BURIED IN HIS HANDS WITH HEAVING CHEST AND RESTLESS LIMBS\n",
            "[-0.00704956 -0.00784302 -0.00015259 ... -0.01657104 -0.00085449\n",
            "  0.0151062 ]\n",
            "THIS HAS INDEED BEEN A HARASSING DAY CONTINUED THE YOUNG MAN HIS EYES FIXED UPON HIS FRIEND\n",
            "[-4.91333008e-03  2.56347656e-03  8.51440430e-03 ... -1.52587891e-03\n",
            " -9.46044922e-04 -6.10351562e-05]\n",
            "YOU WILL BE FRANK WITH ME I ALWAYS AM\n",
            "[-1.22070312e-04  6.40869141e-04 -2.44140625e-04 ...  6.10351562e-05\n",
            "  1.52587891e-03  8.54492188e-04]\n",
            "CAN YOU IMAGINE WHY BUCKINGHAM HAS BEEN SO VIOLENT I SUSPECT\n",
            "[0.00036621 0.00030518 0.00363159 ... 0.0045166  0.00668335 0.00094604]\n",
            "IT IS YOU WHO ARE MISTAKEN RAOUL I HAVE READ HIS DISTRESS IN HIS EYES IN HIS EVERY GESTURE AND ACTION THE WHOLE DAY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the empty lines in the pred.txt\n",
        "with open(\"pred.txt\", \"r\") as infile:\n",
        "    lines = infile.readlines()\n",
        "\n",
        "with open(\"pred.txt\", \"w\") as outfile:\n",
        "    for line in lines:\n",
        "        if line.strip():\n",
        "            outfile.write(line)"
      ],
      "metadata": {
        "id": "uIVyKTIfrk5I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd /root/whisper.cpp/\n",
        "!python /root/wer/main.py pred.txt ref.txt True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iKs3B5JPgkmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a675b0a-78fc-4469-d5f6-cb8395667053"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/whisper.cpp\n",
            "/root\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/wer/main.py\", line 6, in <module>\n",
            "    wer = load(\"wer\")\n",
            "          ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\", line 748, in load\n",
            "    evaluation_module = evaluation_module_factory(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\", line 681, in evaluation_module_factory\n",
            "    raise FileNotFoundError(\n",
            "FileNotFoundError: Couldn't find a module script at /root/wer/wer.py. Module 'wer' doesn't exist on the Hugging Face Hub either.\n"
          ]
        }
      ]
    }
  ]
}