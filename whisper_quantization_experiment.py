# -*- coding: utf-8 -*-
"""Whisper Quantization Experiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NYXsRLmStI-DXOhVhDGPp1RCxh5HDus4
"""

# Commented out IPython magic to ensure Python compatibility.
# Dowloading whisper cpp
# %cd
!git clone https://github.com/ggerganov/whisper.cpp.git
# %cd whisper.cpp
!mkdir build && cd build && cmake .. && make
!sh ./models/download-ggml-model.sh base.en

# build the project
!cmake -B build
!cmake --build build --config Release

# transcribe an audio file
!./build/bin/whisper-cli -f samples/jfk.wav

# Transcribe an audio file and append the output to pred.txt
!./build/bin/whisper-cli -f samples/jfk.wav -otxt >> pred.txt
!cat pred.txt

# quantize a model with Q5_0 method
!cmake -B build
!cmake --build build --config Release
!./build/bin/quantize models/ggml-base.en.bin models/ggml-base.en-q6_0.bin q6_0

!./build/bin/whisper-cli -m models/ggml-base.en-q6_0.bin ./samples/gb0.wav

# downloading huggingface dataset
!git lfs install
!git clone https://huggingface.co/datasets/openslr/librispeech_asr

# Commented out IPython magic to ensure Python compatibility.
# downloading WER program
# %cd
!git clone https://github.com/ins8ai/wer.git
# %cd wer/
!pip install -r requirements.txt

import subprocess
import numpy as np
from scipy.io import wavfile
from datasets import load_dataset

from datasets import load_dataset

# Stream the dataset to avoid full download
dataset_iter = load_dataset("librispeech_asr", "clean", split="test", streaming=True)

# Take only the first 100 samples
dataset = list(dataset_iter.take(100))

print(len(dataset))  # Should print 100
print(dataset[0])  # Check the first sample

# Commented out IPython magic to ensure Python compatibility.
# %cd /root/whisper.cpp/
max_files = 10
current_file_count = 0
whisper_path = "/root/whisper.cpp/build/bin/whisper-cli"
model_path = "/root/whisper.cpp/models/ggml-base.en.bin"
output_file = "pred.txt"
reference_file = "ref.txt"
audio_path = ""
subprocess.run(f"rm {output_file}", shell=True)
subprocess.run(f"rm {reference_file}", shell=True)


for data in dataset:
    if current_file_count >= max_files:
        break
    current_file_count += 1
    audio_data = data["audio"]["array"]
    text_data = data["text"]
    print(audio_data)
    print(text_data)
    audio_data = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)
    wavfile.write('tmp.wav', data['audio']['sampling_rate'], audio_data)

    result = subprocess.run(
        f"{whisper_path} -m {model_path} -f tmp.wav -nt -np >> {output_file} 2>&1",
        shell=True
    )
    with open(reference_file, "a") as f:
        f.write(text_data + "\n")

# delete the empty lines in the pred.txt
with open("pred.txt", "r") as infile:
    lines = infile.readlines()

with open("pred.txt", "w") as outfile:
    for line in lines:
        if line.strip():
            outfile.write(line)

# Commented out IPython magic to ensure Python compatibility.
# %cd
# %cd /root/whisper.cpp/
!python wer/main.py pred.txt ref.txt True